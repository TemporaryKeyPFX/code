{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x6F4OoIYdrZ",
        "outputId": "8a7cd020-e951-4aa8-e264-fe29c14e1bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix_mul.cu\n",
        "//lab 7\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <iomanip>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matMulKernel(float* A, float* B, float* C, int N, int TILE_SIZE) {\n",
        "    extern __shared__ float shared[];\n",
        "    float* tileA = shared;\n",
        "    float* tileB = &shared[TILE_SIZE * TILE_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int i = 0; i < (N + TILE_SIZE - 1) / TILE_SIZE; ++i) {\n",
        "        int tiledRow = row;\n",
        "        int tiledCol = i * TILE_SIZE + threadIdx.x;\n",
        "        if (tiledRow < N && tiledCol < N)\n",
        "            tileA[threadIdx.y * TILE_SIZE + threadIdx.x] = A[tiledRow * N + tiledCol];\n",
        "        else\n",
        "            tileA[threadIdx.y * TILE_SIZE + threadIdx.x] = 0.0f;\n",
        "\n",
        "        tiledRow = i * TILE_SIZE + threadIdx.y;\n",
        "        tiledCol = col;\n",
        "        if (tiledRow < N && tiledCol < N)\n",
        "            tileB[threadIdx.y * TILE_SIZE + threadIdx.x] = B[tiledRow * N + tiledCol];\n",
        "        else\n",
        "            tileB[threadIdx.y * TILE_SIZE + threadIdx.x] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int j = 0; j < TILE_SIZE; ++j)\n",
        "            sum += tileA[threadIdx.y * TILE_SIZE + j] * tileB[j * TILE_SIZE + threadIdx.x];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < N && col < N)\n",
        "        C[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "void printMatrix(float* M, int N, const string& name) {\n",
        "    cout << name << \":\\n\";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j)\n",
        "            cout << setw(5) << M[i * N + j] << \" \";\n",
        "        cout << \"\\n\";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N;\n",
        "    cin >> N;\n",
        "\n",
        "    size_t size = N * N * sizeof(float);\n",
        "    float* A = new float[N * N];\n",
        "    float* B = new float[N * N];\n",
        "    float* C = new float[N * N];\n",
        "\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        A[i] = rand() % 5;\n",
        "        B[i] = rand() % 5;\n",
        "    }\n",
        "\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "    int maxThreads = prop.maxThreadsPerBlock;\n",
        "    int TILE_SIZE = min(32, (int)sqrt((float)maxThreads));\n",
        "\n",
        "    cout << \"Using TILE_SIZE: \" << TILE_SIZE << endl;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 block(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 grid((N + TILE_SIZE - 1) / TILE_SIZE, (N + TILE_SIZE - 1) / TILE_SIZE);\n",
        "    size_t sharedMemSize = 2 * TILE_SIZE * TILE_SIZE * sizeof(float);\n",
        "\n",
        "    matMulKernel<<<grid, block, sharedMemSize>>>(d_A, d_B, d_C, N, TILE_SIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printMatrix(A, N, \"Matrix A\");\n",
        "    printMatrix(B, N, \"Matrix B\");\n",
        "    printMatrix(C, N, \"Matrix C (A x B)\");\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_mul.cu -o matrix_mul\n"
      ],
      "metadata": {
        "id": "5Ttj6-z5Zb_Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo 2 > input.txt  # You can change 512 to any N\n",
        "\n"
      ],
      "metadata": {
        "id": "mAO6F_DMZeEH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul < input.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6UDzYkyaBJO",
        "outputId": "639e801d-818a-4695-a39c-777b8309e978"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TILE_SIZE: 32\n",
            "Matrix A:\n",
            "    3     2 \n",
            "    3     1 \n",
            "\n",
            "Matrix B:\n",
            "    1     0 \n",
            "    0     2 \n",
            "\n",
            "Matrix C (A x B):\n",
            "    0     0 \n",
            "    0     0 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}